{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba21d85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "import scipy.stats as scs\n",
    "import matplotlib.pyplot as plt \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f9cfe0",
   "metadata": {},
   "source": [
    "________________________________\n",
    "\n",
    "### Загрузка .CSV из Tilda ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbde1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "shh = pd.read_csv('Tilda_web_13_10.csv')\n",
    "#shh = data[[\"email\", \"referer\", \"property_id\"]]\n",
    "shh = shh[shh[\"property_id\"] == \"webinar-data-science-13-10-22\"] # вывожу только нужный вебинар"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d87d73",
   "metadata": {},
   "source": [
    "___________________\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d397514",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#   db=shh[shh.duplicated()] #выведение дублей в отдельный столбец\n",
    "res = shh.drop_duplicates(subset=['email'], keep='first') # удаление дубликатов из датафрейма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd4041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ['тут был список тестовых имейлов'] \n",
    "# список тестовых мейлов вряд ли всех...\n",
    "\n",
    "res = res[~res['email'].isin(test)] # удаление этого списка из рабочего датафрейма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79eeab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shh1 = res[res[\"property_id\"] == \"webinar-data-science-13-10-22\"] # вывожу только нужный вебинар\n",
    "clear_mails = res[[\"email\"]] # вывожу только нужные значения\n",
    "\n",
    "a = clear_mails.email.str.lower() #смена регистра, для очистки всех дублей\n",
    "clear_mails['email2'] = a\n",
    "clear_mails = clear_mails.drop(['email'], axis = 1)\n",
    "clear_mails = clear_mails.rename(columns={'email2': 'email'}) # переименовываю"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba34f328",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ref = res['referer'].str.split('?', expand=True) # раскидываю реферер по ютмкам через знак вопроса\n",
    "ref.columns = ['referer', 'utm'] # даю название новым столбцам\n",
    "ref1 = ref['utm'].str.split('&', expand=True) # разделяю теперь ютмки по & \n",
    "ref1.columns = ['source', 'medium' , 'campaign', 'content', 'term' , 'clid', 'wtf'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4362e388",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ref1.columns:\n",
    "    ref1[column] = ref1[column].str.replace('utm_source=' ,' ')\n",
    "    ref1[column] = ref1[column].str.replace('utm_medium=', ' ')  # цикл на удаление ключей меток\n",
    "    ref1[column] = ref1[column].str.replace('utm_campaign=', ' ')\n",
    "    ref1[column] = ref1[column].str.replace('#Inscrever','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcbc74a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#ref1['source'] = np.where (ref1['source'].str.startswith('fbclid='), 'facebook_w', ref1['source']) # решение Санька на удаление fbclid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bbcbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref2 = ref1.fillna(value= '-') # заполняю None тирешками, чтобы считались тоже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad0fbd5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clear_utm = ref2[['source', 'medium', 'campaign']] # присваиваю новые названия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79490cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Reg = pd.concat([clear_mails, clear_utm],axis=1) # конкатенирую две таблицы\n",
    "Reg = Reg[['source', 'medium', 'campaign', 'email']] # меняю порядок столбцов\n",
    "Reg = Reg.rename(columns={'email': 'email_tilda'}) # переименовываю\n",
    "#Reg = Reg.sort_values(by = ['source'], ascending = False).reset_index(drop = True)\n",
    "#Reg = Reg.set_index(['source','medium', 'campaign'])\n",
    "#Reg.to_csv('test123_reg123.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011944d2",
   "metadata": {},
   "source": [
    "__________\n",
    "### Загрузка .CSV из Webinars ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da14f59",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data5 = pd.read_csv('Atendees_13_10.csv')\n",
    "Atendees = data5[['Email']]\n",
    "\n",
    "\n",
    "b = Atendees.Email.str.lower() #смена регистра, для очистки всех дублей\n",
    "Atendees['Email2'] = b\n",
    "Atendees = Atendees.drop(['Email'], axis = 1)\n",
    "Atendees = Atendees.rename(columns={'Email2': 'email_atendees'})\n",
    "#Atendees.to_csv('test_aten.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370c6e91",
   "metadata": {},
   "source": [
    "______\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12582c2",
   "metadata": {},
   "source": [
    "__________\n",
    "### Загрузка .CSV из amo ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d5bab0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data6 = pd.read_csv('amo_webinar_13_10.csv')\n",
    "amo = data6[['Work email']]\n",
    "amo = amo.rename(columns={'Work email': 'email_amo'})\n",
    "\n",
    "c = amo.email_amo.str.lower()\n",
    "amo['email_amo2'] = c\n",
    "amo = amo.drop(['email_amo'], axis = 1)\n",
    "amo = amo.rename(columns={'email_amo2': 'email_amo'})\n",
    "\n",
    "\n",
    "#amo.to_csv('amo_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6574e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "testik  = Atendees.merge(amo, left_on=['email_atendees'], right_on=['email_amo'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08769d2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "final = pd.merge(Reg, testik, left_on=['email_tilda'], right_on=['email_atendees'], how='left')\n",
    "    #]final.insert(5, 'two', '.')\n",
    "    #final['two'] = np.where (final['email_atendees'].str.startswith('NaN'), 'NaN', final['two'])\n",
    "    #final1 = pd.merge(final, amo, left_on=['email_atendees'], right_on=['email_amo'], how='left')\n",
    "#final1 = final.groupby(['source', 'medium', 'campaign']).count()\n",
    "    #final1 = final1.drop(['one'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e87fea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044c6144",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('Webinar_tst_WOW_REALLY!!!!!!.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
